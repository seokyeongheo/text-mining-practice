{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import getpass\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Google ID :  syh602@gmail.com\n",
      "Enter Google PW :  ········\n"
     ]
    }
   ],
   "source": [
    "# log-in\n",
    "\n",
    "insert_id = input('Enter Google ID : ')\n",
    "insert_pw = getpass.getpass('Enter Google PW : ')\n",
    "\n",
    "url = \"https://www.rocketpunch.com/login\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "login_google = driver.find_element_by_xpath('//*[@id=\"login-main\"]/div[3]/a[2]')\n",
    "login_google.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "google_id = driver.find_element_by_xpath('//*[@id=\"identifierId\"]')\n",
    "google_id.send_keys(insert_id)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "google_id_submit = driver.find_element_by_xpath('//*[@id=\"identifierNext\"]/content')\n",
    "google_id_submit.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "google_pw = driver.find_element_by_xpath('//*[@id=\"password\"]/div[1]/div/div[1]/input')\n",
    "google_pw.send_keys(insert_pw)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "google_pw_submit = driver.find_element_by_xpath('//*[@id=\"passwordNext\"]/content/span')\n",
    "google_pw_submit.click()\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loop is ended. You have 10 bookmarks.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.rocketpunch.com/@quartz/bookmark\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# get page sourse, parse html\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "date_list = []\n",
    "company_list = []\n",
    "job_list = []\n",
    "salary_list = []\n",
    "condition_list = []\n",
    "special_list = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    try:\n",
    "        date = soup.findAll('div', {'class': 'job-dates'})\n",
    "        date = date[i].text.split(\"\\n\")[2].strip()\n",
    "        date_list.append(date)\n",
    "\n",
    "        company = soup.findAll('div', {'class': 'company-name'})\n",
    "        company = company[i].text.split('\\n')[2].strip()\n",
    "        company_list.append(company)\n",
    "\n",
    "        job = soup.findAll('a', {'class': 'nowrap job-title'})\n",
    "        job = job[i].text\n",
    "        job_list.append(job)\n",
    "\n",
    "        salary_condition = soup.findAll('div', {'class': 'job-stat-info'})\n",
    "        salary = salary_condition[i].text.split(\"/\")[0].strip()\n",
    "        condition = salary_condition[i].text.split(\"/\")[1].strip()\n",
    "        salary_list.append(salary)\n",
    "        condition_list.append(condition)\n",
    "\n",
    "        special = soup.findAll('div', {'class': 'nowrap job-specialties'})\n",
    "        special = special[i].text\n",
    "        special_list.append(special)\n",
    "    except:\n",
    "        print(\"The loop is ended. You have %d bookmarks.\" % (i))\n",
    "        break\n",
    "    \n",
    "data_job = pd.DataFrame(columns=['date', 'company', 'job', 'salary', 'condition', 'special'])\n",
    "data_job['date'] = date_list\n",
    "data_job['company'] = company_list\n",
    "data_job['job'] = job_list\n",
    "data_job['salary'] = salary_list\n",
    "data_job['condition'] = condition_list\n",
    "data_job['special'] = special_list\n",
    "data_job.to_excel('rocketpunch_bookmark.xlsx', sheet_name='rocketpunch_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>job</th>\n",
       "      <th>salary</th>\n",
       "      <th>condition</th>\n",
       "      <th>special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/31 마감</td>\n",
       "      <td>케이씨 ML2(KC ML2)</td>\n",
       "      <td>Research Resident (Internship)</td>\n",
       "      <td>3,500 - 6,000만원</td>\n",
       "      <td>인턴, 신입, 경력</td>\n",
       "      <td>Python ∙ Git</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/14 마감</td>\n",
       "      <td>라인웍스</td>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>최소 3,000만원</td>\n",
       "      <td>신입, 경력</td>\n",
       "      <td>데이터분석 ∙ 빅데이터 ∙ data-analysis ∙ research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02/11 마감</td>\n",
       "      <td>닛픽(NITPICK)</td>\n",
       "      <td>데이터 사이언티스트(텍스트 데이터 분석가) 모집</td>\n",
       "      <td>2,400 - 3,000만원</td>\n",
       "      <td>인턴, 신입</td>\n",
       "      <td>Data Science ∙ data-analysis ∙ Datamining ∙ te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수시채용</td>\n",
       "      <td>밸런스히어로(Balance Hero)</td>\n",
       "      <td>Junior Business Analyst</td>\n",
       "      <td>연봉 미기재</td>\n",
       "      <td>인턴, 신입, 경력</td>\n",
       "      <td>데이터분석 ∙ 데이터 ∙ 데이터관리 ∙ 지표분석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>수시채용</td>\n",
       "      <td>코드잇(codeit)</td>\n",
       "      <td>퍼포먼스 마케터 / 그로스해커</td>\n",
       "      <td>2,400 - 4,200만원</td>\n",
       "      <td>최대 1.0%</td>\n",
       "      <td>온라인마케팅 ∙ 디지털마케팅 ∙ 그로스해킹 ∙ Google Analytics ∙ 페...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>수시채용</td>\n",
       "      <td>피카소(Picasso)</td>\n",
       "      <td>유튜브 빅데이터 스타트업 _ 함께 성장할 데이터 애널리스트분 모십니다.</td>\n",
       "      <td>3,600 - 4,000만원</td>\n",
       "      <td>1.0 - 5.0%</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>수시채용</td>\n",
       "      <td>모루랩스(Moru Labs)</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>3,500 - 5,000만원</td>\n",
       "      <td>신입, 경력</td>\n",
       "      <td>Python ∙ Git ∙ Pandas ∙ scikit-learn ∙ TensorF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01/31 마감</td>\n",
       "      <td>데이터크런치(Datacrunch)</td>\n",
       "      <td>Data Analyst / Data Scientist</td>\n",
       "      <td>5,000 - 10,000만원</td>\n",
       "      <td>인턴, 신입, 경력</td>\n",
       "      <td>MySQL ∙ Python ∙ SQL ∙ 빅데이터 ∙ 빅데이터 분석/인프라/가시화 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>수시채용</td>\n",
       "      <td>마이셀럽스(mycelebs)</td>\n",
       "      <td>그로스해커/데이터 전처리/서비스 기획 및 운영 인턴 모집</td>\n",
       "      <td>연봉 미기재</td>\n",
       "      <td>0.05 - 0.2%</td>\n",
       "      <td>서비스운영 ∙ 데이터분석 ∙ 데이터수집 ∙ 데이터관리 ∙ 통계분석 ∙ 운영 ∙ 서비...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>수시채용</td>\n",
       "      <td>휴멜로(Humelo)</td>\n",
       "      <td>[인턴직] ML / Deep Learning Researcher (2019.3월 입...</td>\n",
       "      <td>연봉 미기재</td>\n",
       "      <td>인턴</td>\n",
       "      <td>deep-learning ∙ Machine Learning  ∙ Data Scien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date               company  \\\n",
       "0  01/31 마감       케이씨 ML2(KC ML2)   \n",
       "1  02/14 마감                  라인웍스   \n",
       "2  02/11 마감           닛픽(NITPICK)   \n",
       "3      수시채용  밸런스히어로(Balance Hero)   \n",
       "4      수시채용           코드잇(codeit)   \n",
       "5      수시채용          피카소(Picasso)   \n",
       "6      수시채용       모루랩스(Moru Labs)   \n",
       "7  01/31 마감    데이터크런치(Datacrunch)   \n",
       "8      수시채용       마이셀럽스(mycelebs)   \n",
       "9      수시채용           휴멜로(Humelo)   \n",
       "\n",
       "                                                 job            salary  \\\n",
       "0                     Research Resident (Internship)   3,500 - 6,000만원   \n",
       "1                                            데이터 분석가        최소 3,000만원   \n",
       "2                         데이터 사이언티스트(텍스트 데이터 분석가) 모집   2,400 - 3,000만원   \n",
       "3                            Junior Business Analyst            연봉 미기재   \n",
       "4                                   퍼포먼스 마케터 / 그로스해커   2,400 - 4,200만원   \n",
       "5            유튜브 빅데이터 스타트업 _ 함께 성장할 데이터 애널리스트분 모십니다.   3,600 - 4,000만원   \n",
       "6                                     data scientist   3,500 - 5,000만원   \n",
       "7                      Data Analyst / Data Scientist  5,000 - 10,000만원   \n",
       "8                    그로스해커/데이터 전처리/서비스 기획 및 운영 인턴 모집            연봉 미기재   \n",
       "9  [인턴직] ML / Deep Learning Researcher (2019.3월 입...            연봉 미기재   \n",
       "\n",
       "     condition                                            special  \n",
       "0   인턴, 신입, 경력                                       Python ∙ Git  \n",
       "1       신입, 경력            데이터분석 ∙ 빅데이터 ∙ data-analysis ∙ research  \n",
       "2       인턴, 신입  Data Science ∙ data-analysis ∙ Datamining ∙ te...  \n",
       "3   인턴, 신입, 경력                         데이터분석 ∙ 데이터 ∙ 데이터관리 ∙ 지표분석  \n",
       "4      최대 1.0%  온라인마케팅 ∙ 디지털마케팅 ∙ 그로스해킹 ∙ Google Analytics ∙ 페...  \n",
       "5   1.0 - 5.0%                                             Python  \n",
       "6       신입, 경력  Python ∙ Git ∙ Pandas ∙ scikit-learn ∙ TensorF...  \n",
       "7   인턴, 신입, 경력  MySQL ∙ Python ∙ SQL ∙ 빅데이터 ∙ 빅데이터 분석/인프라/가시화 ...  \n",
       "8  0.05 - 0.2%  서비스운영 ∙ 데이터분석 ∙ 데이터수집 ∙ 데이터관리 ∙ 통계분석 ∙ 운영 ∙ 서비...  \n",
       "9           인턴  deep-learning ∙ Machine Learning  ∙ Data Scien...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페이지 하나씩 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.rocketpunch.com/@quartz/bookmark\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = driver.find_elements_by_xpath('//*[@id=\"wrap\"]/div/div[2]/div/div/div[1]/div[1]/div/div[1]/a')\n",
    "\n",
    "n = len(titles)\n",
    "\n",
    "# scraping each page\n",
    "titles[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Google ID :  syh602\n",
      "Enter Google PW :  ········\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'WebElement' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-ab157a80b8d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mgoogle_pw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//*[@id=\"password\"]/div[1]/div/div[1]/input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mgoogle_pw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoogle_pw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36msend_keys\u001b[0;34m(self, *value)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         self._execute(Command.SEND_KEYS_TO_ELEMENT,\n\u001b[0;32m--> 478\u001b[0;31m                       {'text': \"\".join(keys_to_typing(value)),\n\u001b[0m\u001b[1;32m    479\u001b[0m                        'value': keys_to_typing(value)})\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/selenium/webdriver/common/utils.py\u001b[0m in \u001b[0;36mkeys_to_typing\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'WebElement' has no len()"
     ]
    }
   ],
   "source": [
    "# SETUP\n",
    "import getpass\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# log-in\n",
    "\n",
    "google_id = input('Enter Google ID : ')\n",
    "google_pw = getpass.getpass('Enter Google PW : ')\n",
    "\n",
    "url = \"https://www.rocketpunch.com/login\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "login_google = driver.find_element_by_xpath('//*[@id=\"login-main\"]/div[3]/a[2]')\n",
    "login_google.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "google_id = driver.find_element_by_xpath('//*[@id=\"identifierId\"]')\n",
    "google_id.send_keys(\"syh602\")\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "google_id_submit = driver.find_element_by_xpath('//*[@id=\"identifierNext\"]/content')\n",
    "google_id_submit.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "google_pw = driver.find_element_by_xpath('//*[@id=\"password\"]/div[1]/div/div[1]/input')\n",
    "google_pw.send_keys(google_pw)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "google_pw_submit = driver.find_element_by_xpath('//*[@id=\"passwordNext\"]/content/span')\n",
    "google_pw_submit.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# get bookmark url\n",
    "\n",
    "url = \"https://www.rocketpunch.com/@quartz/bookmark\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# get page sourse, parse html\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "date_list = []\n",
    "company_list = []\n",
    "job_list = []\n",
    "salary_list = []\n",
    "condition_list = []\n",
    "special_list = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    try:\n",
    "        date = soup.findAll('div', {'class': 'job-dates'})\n",
    "        date = date[i].text.split(\"\\n\")[2].strip()\n",
    "        date_list.append(date)\n",
    "\n",
    "        company = soup.findAll('div', {'class': 'company-name'})\n",
    "        company = company[i].text.split('\\n')[2].strip()\n",
    "        company_list.append(company)\n",
    "\n",
    "        job = soup.findAll('a', {'class': 'nowrap job-title'})\n",
    "        job = job[i].text\n",
    "        job_list.append(job)\n",
    "\n",
    "        salary_condition = soup.findAll('div', {'class': 'job-stat-info'})\n",
    "        salary = salary_condition[i].text.split(\"/\")[0].strip()\n",
    "        condition = salary_condition[i].text.split(\"/\")[1].strip()\n",
    "        salary_list.append(salary)\n",
    "        condition_list.append(condition)\n",
    "\n",
    "        special = soup.findAll('div', {'class': 'nowrap job-specialties'})\n",
    "        special = special[i].text\n",
    "        special_list.append(special)\n",
    "    except:\n",
    "        print(\"The loop is ended. You have %d bookmarks.\" % (i))\n",
    "        break\n",
    "\n",
    "# make dataframe, xlsx file\n",
    "data_job = pd.DataFrame(columns=['date', 'company', 'job', 'salary', 'condition', 'special'])\n",
    "data_job['date'] = date_list\n",
    "data_job['company'] = company_list\n",
    "data_job['job'] = job_list\n",
    "data_job['salary'] = salary_list\n",
    "data_job['condition'] = condition_list\n",
    "data_job['special'] = special_list\n",
    "data_job.to_excel('rocketpunch_bookmark.xlsx', sheet_name='rocketpunch_01')\n",
    "\n",
    "# quit\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
